{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1789720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "093087cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "algos = ['DQN', 'BCQ', 'CQL']\n",
    "nr_trajs = [100, 1000, 10000, 50000, 100000]\n",
    "opts = [0, 25, 50, 75, 100]\n",
    "seeds = range(1, 4)\n",
    "\n",
    "base_path = 'maintenance_offlineRL/d3rlpy_logs'\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a460d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the best configuration for each statistic\n",
    "def find_best_for_statistic(statistic, value):\n",
    "    if statistic == 'algo':\n",
    "        best = results_df[results_df['algo'] == value].sort_values(by='avg_reward', ascending=False).iloc[0]\n",
    "    elif statistic == 'opt':\n",
    "        best = results_df[results_df['opt'] == value].sort_values(by='avg_reward', ascending=False).iloc[0]\n",
    "    elif statistic == 'nr_traj':\n",
    "        best = results_df[results_df['nr_traj'] == value].sort_values(by='avg_reward', ascending=False).iloc[0]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26285095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimality 0: Best Algo: CQL, Dataset Size: 1000, Avg Reward: -14405.35, Std Error: 144.68, Best Timestep: 40000.0\n",
      "Optimality 25: Best Algo: CQL, Dataset Size: 100, Avg Reward: -14972.62, Std Error: 215.49, Best Timestep: 60000.0\n",
      "Optimality 50: Best Algo: CQL, Dataset Size: 100, Avg Reward: -15490.48, Std Error: 155.10, Best Timestep: 60000.0\n",
      "Optimality 75: Best Algo: CQL, Dataset Size: 10000, Avg Reward: -15306.57, Std Error: 422.60, Best Timestep: 70000.0\n",
      "Optimality 100: Best Algo: BCQ, Dataset Size: 100000, Avg Reward: -15419.07, Std Error: 352.74, Best Timestep: 100000.0\n",
      "Algorithm DQN: Best Optimality: 0, Dataset Size: 10000, Avg Reward: -16942.37, Std Error: 491.28, Best Timestep: 100000.0\n",
      "Algorithm BCQ: Best Optimality: 100, Dataset Size: 100000, Avg Reward: -15419.07, Std Error: 352.74, Best Timestep: 100000.0\n",
      "Algorithm CQL: Best Optimality: 0, Dataset Size: 1000, Avg Reward: -14405.35, Std Error: 144.68, Best Timestep: 40000.0\n",
      "Dataset Size 100: Best Algo: CQL, Optimality: 25, Avg Reward: -14972.62, Std Error: 215.49, Best Timestep: 60000.0\n",
      "Dataset Size 1000: Best Algo: CQL, Optimality: 0, Avg Reward: -14405.35, Std Error: 144.68, Best Timestep: 40000.0\n",
      "Dataset Size 10000: Best Algo: CQL, Optimality: 0, Avg Reward: -14744.30, Std Error: 202.85, Best Timestep: 20000.0\n",
      "Dataset Size 50000: Best Algo: CQL, Optimality: 25, Avg Reward: -15315.69, Std Error: 111.94, Best Timestep: 70000.0\n",
      "Dataset Size 100000: Best Algo: CQL, Optimality: 25, Avg Reward: -15295.83, Std Error: 376.92, Best Timestep: 60000.0\n"
     ]
    }
   ],
   "source": [
    "# Load the data and calculate averages and standard errors\n",
    "for algo in algos:\n",
    "    for opt in opts:\n",
    "        for nr_traj in nr_trajs:\n",
    "            timestep_rewards = {}\n",
    "            for seed in seeds:\n",
    "                file_path = f'{base_path}/{algo}_nr_traj_{nr_traj}_opt_{opt}_seed_{seed}/evaluation_env.csv'\n",
    "                if os.path.exists(file_path):\n",
    "                    df = pd.read_csv(file_path, header=None, sep=',', names=['Row', 'Timestep', 'Return', 'Variance', 'StandardError'])\n",
    "                    for index, row in df.iterrows():\n",
    "                        timestep = row['Timestep']\n",
    "                        reward = row['Return']\n",
    "                        if timestep not in timestep_rewards:\n",
    "                            timestep_rewards[timestep] = []\n",
    "                        timestep_rewards[timestep].append(reward)\n",
    "            \n",
    "            # Calculate average reward for each timestep across seeds\n",
    "            avg_rewards = {t: np.mean(r) for t, r in timestep_rewards.items() if len(r) == len(seeds)}\n",
    "            \n",
    "            if avg_rewards:\n",
    "                best_timestep = max(avg_rewards, key=avg_rewards.get)\n",
    "                rewards_at_best_timestep = timestep_rewards[best_timestep]\n",
    "                avg_reward = np.mean(rewards_at_best_timestep)\n",
    "                std_error = np.std(rewards_at_best_timestep) / np.sqrt(len(rewards_at_best_timestep))\n",
    "                results.append({\n",
    "                    'algo': algo,\n",
    "                    'opt': opt,\n",
    "                    'nr_traj': nr_traj,\n",
    "                    'avg_reward': avg_reward,\n",
    "                    'std_error': std_error,\n",
    "                    'best_timestep': best_timestep\n",
    "                })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find the best configuration for each optimality rate\n",
    "for opt in opts:\n",
    "    best_config = find_best_for_statistic('opt', opt)\n",
    "    print(f\"Optimality {opt}: Best Algo: {best_config['algo']}, Dataset Size: {best_config['nr_traj']}, \"\n",
    "          f\"Avg Reward: {best_config['avg_reward']:.2f}, Std Error: {best_config['std_error']:.2f}, \"\n",
    "          f\"Best Timestep: {best_config['best_timestep']}\")\n",
    "\n",
    "# Find the best configuration for each algorithm\n",
    "for algo in algos:\n",
    "    best_config = find_best_for_statistic('algo', algo)\n",
    "    print(f\"Algorithm {algo}: Best Optimality: {best_config['opt']}, Dataset Size: {best_config['nr_traj']}, \"\n",
    "          f\"Avg Reward: {best_config['avg_reward']:.2f}, Std Error: {best_config['std_error']:.2f}, \"\n",
    "          f\"Best Timestep: {best_config['best_timestep']}\")\n",
    "\n",
    "# Find the best configuration for each dataset size\n",
    "for nr_traj in nr_trajs:\n",
    "    best_config = find_best_for_statistic('nr_traj', nr_traj)\n",
    "    print(f\"Dataset Size {nr_traj}: Best Algo: {best_config['algo']}, Optimality: {best_config['opt']}, \"\n",
    "          f\"Avg Reward: {best_config['avg_reward']:.2f}, Std Error: {best_config['std_error']:.2f}, \"\n",
    "          f\"Best Timestep: {best_config['best_timestep']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3db3db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimality 0: Best Algo: CQL, Dataset Size: 100000, Avg Reward: -43096.87, Std Error: 6940.26\n",
      "Optimality 25: Best Algo: CQL, Dataset Size: 50000, Avg Reward: -29644.84, Std Error: 3695.05\n",
      "Optimality 50: Best Algo: CQL, Dataset Size: 10000, Avg Reward: -37861.74, Std Error: 4636.49\n",
      "Optimality 75: Best Algo: CQL, Dataset Size: 100, Avg Reward: -19852.71, Std Error: 1499.97\n",
      "Optimality 100: Best Algo: BCQ, Dataset Size: 100000, Avg Reward: -16909.75, Std Error: 95.39\n",
      "Algorithm DQN: Best Optimality: 0, Dataset Size: 10000, Avg Reward: -103094.31, Std Error: 2669.72\n",
      "Algorithm BCQ: Best Optimality: 100, Dataset Size: 100000, Avg Reward: -16909.75, Std Error: 95.39\n",
      "Algorithm CQL: Best Optimality: 100, Dataset Size: 50000, Avg Reward: -19310.15, Std Error: 1201.18\n",
      "Dataset Size 100: Best Algo: BCQ, Optimality: 100, Avg Reward: -18718.97, Std Error: 1010.66\n",
      "Dataset Size 1000: Best Algo: BCQ, Optimality: 100, Avg Reward: -16985.62, Std Error: 115.11\n",
      "Dataset Size 10000: Best Algo: BCQ, Optimality: 100, Avg Reward: -16916.59, Std Error: 155.45\n",
      "Dataset Size 50000: Best Algo: BCQ, Optimality: 100, Avg Reward: -17235.69, Std Error: 252.77\n",
      "Dataset Size 100000: Best Algo: BCQ, Optimality: 100, Avg Reward: -16909.75, Std Error: 95.39\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameters\n",
    "algos = ['DQN', 'BCQ', 'CQL']\n",
    "nr_trajs = [100, 1000, 10000, 50000, 100000]\n",
    "opts = [0, 25, 50, 75, 100]\n",
    "seeds = range(1, 4)\n",
    "\n",
    "base_path = 'maintenance_offlineRL/d3rlpy_logs'\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = []\n",
    "\n",
    "# Load the data and calculate averages and standard errors\n",
    "for algo in algos:\n",
    "    for opt in opts:\n",
    "        for nr_traj in nr_trajs:\n",
    "            seed_averages = []\n",
    "            for seed in seeds:\n",
    "                file_path = f'{base_path}/{algo}_nr_traj_{nr_traj}_opt_{opt}_seed_{seed}/evaluation_env.csv'\n",
    "                if os.path.exists(file_path):\n",
    "                    df = pd.read_csv(file_path, header=None, sep=',', names=['Row', 'Timestep', 'Return', 'Variance', 'StandardError'])\n",
    "                    avg_return = df['Return'].mean()  # Average return across all timesteps\n",
    "                    seed_averages.append(avg_return)\n",
    "            if seed_averages:\n",
    "                avg_reward = np.mean(seed_averages)\n",
    "                std_error = np.std(seed_averages) / np.sqrt(len(seed_averages))\n",
    "                results.append({\n",
    "                    'algo': algo,\n",
    "                    'opt': opt,\n",
    "                    'nr_traj': nr_traj,\n",
    "                    'avg_reward': avg_reward,\n",
    "                    'std_error': std_error\n",
    "                })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find the best configuration for each optimality rate\n",
    "for opt in opts:\n",
    "    best_config = find_best_for_statistic('opt', opt)\n",
    "    print(f\"Optimality {opt}: Best Algo: {best_config['algo']}, Dataset Size: {best_config['nr_traj']}, \"\n",
    "          f\"Avg Reward: {best_config['avg_reward']:.2f}, Std Error: {best_config['std_error']:.2f}\")\n",
    "\n",
    "# Find the best configuration for each algorithm\n",
    "for algo in algos:\n",
    "    best_config = find_best_for_statistic('algo', algo)\n",
    "    print(f\"Algorithm {algo}: Best Optimality: {best_config['opt']}, Dataset Size: {best_config['nr_traj']}, \"\n",
    "          f\"Avg Reward: {best_config['avg_reward']:.2f}, Std Error: {best_config['std_error']:.2f}\")\n",
    "\n",
    "# Find the best configuration for each dataset size\n",
    "for nr_traj in nr_trajs:\n",
    "    best_config = find_best_for_statistic('nr_traj', nr_traj)\n",
    "    print(f\"Dataset Size {nr_traj}: Best Algo: {best_config['algo']}, Optimality: {best_config['opt']}, \"\n",
    "          f\"Avg Reward: {best_config['avg_reward']:.2f}, Std Error: {best_config['std_error']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af56a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
